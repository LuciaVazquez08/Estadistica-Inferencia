{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Modelo de Regresión Lineal General\n",
        "\n",
        "En clases pasadas vimos que la forma más sencilla de modelar la relación entre dos (o más) variables consiste en asumir que la relación entre ambas variables es fundamentalmente lineal.\n",
        "\n",
        "Específicamente, en el contexto de modelos probabilísticos, asumimos que\n",
        "\n",
        "$$ Y  = \\mu(X) + \\varepsilon $$\n",
        "\n",
        "Donde:\n",
        "* $\\mu(X) = X\\boldsymbol{\\beta}$\n",
        "* $\\varepsilon | X \\sim i.i.d. \\mathcal{N} (0, \\sigma^2)$  \n",
        "\n",
        "Es decir,\n",
        "$$ Y = X\\beta + \\varepsilon$$\n",
        "con\n",
        "$$ Y | X \\sim  \\mathcal{N} (\\mu(X), \\sigma^2)$$\n",
        "  \n",
        "---\n",
        "Si tomamos $n$ samples de $Y$ y $X$, podemos expresar la relación como\n",
        "\n",
        "$$ \\mathbf{y} = \\mathbb{X}\\boldsymbol{\\beta} + \\boldsymbol{\\varepsilon}$$\n",
        "\n",
        "\n",
        "donde:\n",
        "\n",
        "* $\\mathbf{y}$ es el vector de observaciones de la variable dependiente (de tamaño $n\\times1$),\n",
        "*$\\mathbb{X}$ es la matriz de diseño o de regresores (de tamaño $n\\times (p+1)$)\n",
        "* $\\boldsymbol{\\beta}$ es el vector de parámetros a estimar (de tamaño $(p+1)\\times1)$,\n",
        "* $\\boldsymbol{\\varepsilon}$ es el vector de errores aleatorios (de tamaño $n\\times1$).\n",
        "\n",
        "Donde tenemos\n",
        "\n",
        "* $\\mathbb{E}(\\boldsymbol{\\varepsilon} | \\mathbb{X}) = \\mathbf{0}_n$\n",
        "* $\\mathbb{V}(\\boldsymbol{\\varepsilon} | \\mathbb{X}) = \\sigma^2 \\mathbf{I}_n$\n",
        "* $ \\boldsymbol{\\varepsilon} | \\mathbb{X} \\sim  \\mathcal{N} (\\mathbb{X}\\boldsymbol{\\beta},  \\sigma^2 \\mathbf{I}_n)$  \n",
        "  \n",
        "    \n",
        "## Inferencia en el modelo lineal\n",
        "Bajo estos supuestos (y asumiendo que la matriz de diseño tiene rango $p+1$, por lo que $\\mathbb{X}^T\\mathbb{X}$ es una matriz no singular), el estimador de mínimos cuadrados de $\\boldsymbol{\\beta}$ (que coincide con su estimador por máxima verosimilitud) es\n",
        "\n",
        "$$\n",
        "\\hat{\\boldsymbol{\\beta}}= (\\mathbb{X}^T\\mathbb{X})^{-1}\\mathbb{X}^T\\mathbf{y}\n",
        "$$\n",
        "\n",
        "Por lo que\n",
        "\n",
        "$$\n",
        "\\hat{\\boldsymbol{\\beta}} = \\boldsymbol{\\beta} + (\\mathbb{X}^T\\mathbb{X})^{-1}\\mathbb{X}^T\\boldsymbol{\\varepsilon}\n",
        "$$\n",
        "\n",
        "Esta última expresión muestra que, bajo el supuesto de normalidad de los residuos, los estimadores de mínimos cuadrados tienen la distribución\n",
        "\n",
        "$$\\\n",
        "\\hat{\\boldsymbol{\\beta}} | \\mathbb{X} \\sim \\mathcal{N}(\\boldsymbol{\\beta},  \\sigma^2(\\mathbb{X}^T\\mathbb{X})^{-1})\n",
        "$$\n",
        "\n",
        "Este resultado implica que:\n",
        "\n",
        "* **Esperanza:** el estimador es insesgado: $\\mathbb{E}(\\boldsymbol{\\hat\\beta})=\\mathbb{E}(\\boldsymbol{\\hat\\beta}| \\mathbb{X}) = \\boldsymbol{\\beta}$,\n",
        "* **Varianza-Covarianza:** La matriz de varianzas y covarianzas de los estimadores depende de la varianza de los errores $\\sigma$ y de la estructura de los datos \\mathbb{X}. $\\mathbb{V}(\\boldsymbol{\\boldsymbol{\\hat\\beta}} | \\mathbb{X}) = \\sigma^2(\\mathbb{X}^T\\mathbb{X})^{-1}$\n",
        "\n",
        "\n",
        "Dado que los estimadores de MCO son normales, se pueden utilizar distribuciones conocidas para realizar inferencias sobre los parámetros del modelo.\n",
        "\n",
        "Por ejemplo:\n",
        "\n",
        "###Pruebas de hipótesis:\n",
        "#### Para un parámetro específico $\\beta_j$\n",
        "\n",
        "La hipótesis nula $H_0: \\beta_j = \\beta_j^0$ se puede probar utilizando un estadístico $t$, que sigue una distribución t de Student bajo la hipótesis nula.\n",
        "\n",
        " $$\n",
        " t= \\frac{\\hat\\beta_j - \\beta_j^0}{\\hat{SE}(\\hat\\beta_j)} \\sim t_{n-(p+1)}\n",
        " $$\n",
        "\n",
        " donde $\\hat{SE}(\\hat\\beta_j)$ es el error estándar estimado del estimador $\\hat{SE}(\\hat\\beta_j)=\\hat\\sigma \\sqrt{a_{jj}}$ con $a_{jj}$ el elemento correspondiente de la matriz $(\\mathbb{X}^T\\mathbb{X})^{-1}$\n",
        "\n",
        "\n",
        "####Intervalos de confianza:\n",
        "Cuando la varianza de los errores $\\sigma^2$ es deconodida, los intervalos de confianza para los parámetros también pueden construirse a partir de la distribución t de Student, dado un nivel de confianza $1-\\alpha$.\n",
        "\n",
        "$$\\hat\\beta_j \\pm t_{\\alpha/2, n-(p+1)} \\cdot \\hat{SE}(\\hat{\\beta}_j)$$\n",
        "\n",
        "\n",
        "Estos procedimientos permiten extraer conclusiones sobre la relación entre las variables explicativas y la variable dependiente, permitiendo evaluar la significancia estadística de los efectos estimados y construir intervalos de confianza para los parámetros del modelo.\n"
      ],
      "metadata": {
        "id": "KsmztJGlez_p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Estimación de una Curva Salarial\n",
        "\n",
        "Para este ejercicio vamos a analizar los determinantes del salario utilizando un modelo de regresión lineal. El ejercicio se concentra en la estimación e interpretación de los coeficientes. Para eso, vamos a trabajar la base de datos \"wage1.txt\" del libro de *Introducción a la Econometría* de Wooldridge(2009), que es una parte de una base de datos de corte transversal de 526 trabajadores de Estados Unidos correspondientes a 1976.\n",
        "\n",
        "Se pide:\n",
        "\n",
        "i. Graficar los histogramas de las variables *wage* y *lwage*, que tienen los salarios horarios promedio del año y su logaritmo y argumentar por qué tiene más sentido considerar modelar la variable *lwage*.  \n",
        "\n",
        "ii. Estimar el modelo $lwage \\sim educ + exper + expersq + female$.\n",
        "\n",
        "iii. Estimar el error irreducible del modelo $\\sigma^2$\n",
        "\n",
        "iv. Estimar la variación esperada sobre el logaritmo del salario del sexo con una confianza del 95%.\n",
        "\n",
        "v. Realizar una prueba de hipótesis para evaluar si la educación y el sexo tienen un efecto estadísticamente significativo sobre el salario.\n"
      ],
      "metadata": {
        "id": "mOGIqMu-Vwuf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('wage1.txt', sep='\\t')\n"
      ],
      "metadata": {
        "id": "UWbGoqe2jycs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "i. Graficar los histogramas de las variables *wage* y *lwage*, que tienen los salarios horarios promedio del año y su logaritmo y argumentar por qué tiene más sentido considerar modelar la variable *lwage*.  "
      ],
      "metadata": {
        "id": "-MSBQHbmZ2Ki"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Crear figura\n",
        "fig, axs = plt.subplots(1,2,figsize=(12, 5))\n",
        "\n",
        "# Histograma de wage\n",
        "axs[0].hist(df['wage'], bins=15, color='skyblue', edgecolor='black')\n",
        "axs[0].set_title('Distribución de Wage')\n",
        "axs[0].set_xlabel('Salario')\n",
        "axs[0].set_ylabel('Frecuencia')\n",
        "\n",
        "# Histograma de lwage\n",
        "axs[1].hist(df['lwage'], bins=15, color='lightgreen', edgecolor='black')\n",
        "axs[1].set_title('Distribución de Lwage')\n",
        "axs[1].set_xlabel('Logaritmo del Salario')\n",
        "axs[1].set_ylabel('Frecuencia')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "UcLPDPkPWvyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ii. Estimar el modelo $lwage \\sim educ + exper + expersq + female$."
      ],
      "metadata": {
        "id": "InEfUzGtalEg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_beta_hat(X, y):\n",
        "    \"\"\"\n",
        "    Calcula los coeficientes estimados (beta_hat) en un modelo de regresión lineal múltiple.\n",
        "\n",
        "    Parámetros:\n",
        "    X: numpy array de dimensión (n_samples, n_features)\n",
        "       Matriz de diseño (variables independientes), incluyendo la columna de unos para el intercepto.\n",
        "    y: numpy array de dimensión (n_samples,)\n",
        "       Vector de la variable dependiente.\n",
        "\n",
        "    Retorna:\n",
        "    beta_hat: numpy array de dimensión (n_features,)\n",
        "              Vector de coeficientes estimados.\n",
        "    \"\"\"\n",
        "    # Calcular beta_hat usando la fórmula de MCO: β = (X'X)^(-1)X'y\n",
        "    beta_hat = np.linalg.inv(X.T @ X) @ X.T @ y\n",
        "    return beta_hat"
      ],
      "metadata": {
        "id": "lFEVnYtaazQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir variables independientes y dependiente\n",
        "regresores = ['educ', 'exper', 'expersq', 'female']\n",
        "\n",
        "X = df[regresores].values\n",
        "y = df['lwage'].values\n",
        "\n",
        "# Agregar una columna de unos para el intercepto\n",
        "X = np.column_stack((np.ones(X.shape[0]), X))\n",
        "\n",
        "# Estimación de coeficientes mediante la fórmula de MCO: β = (X'X)^(-1)X'y\n",
        "beta_hat = get_beta_hat(X, y)\n",
        "print('Coeficientes estimados:', beta_hat)"
      ],
      "metadata": {
        "id": "t49lE6C9WGvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "iii. Estimar el error irreducible del modelo $\\sigma^2$"
      ],
      "metadata": {
        "id": "nX7CXWRTbaRI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener predicciones (y_hat)\n",
        "y_hat = X @ beta_hat\n",
        "\n",
        "# Obtener los residuos\n",
        "resids = y - y_hat\n",
        "\n",
        "# Obtener SCR (RSS)\n",
        "scr = np.sum(resids**2)\n",
        "\n",
        "# Obtener sigma2_hat\n",
        "sigma2_hat = scr / (X.shape[0] - X.shape[1])\n",
        "\n",
        "print('Error irreducible estimado:', sigma2_hat)"
      ],
      "metadata": {
        "id": "Il4QxGijbeoT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "iv. Estimar la variación esperada sobre el logaritmo del salario del sexo con una confianza del 95%."
      ],
      "metadata": {
        "id": "wMvTxZdkbaOy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener la matriz de varianzas y covarianzas no-escalada\n",
        "XTX_1 = np.linalg.inv(X.T @ X)\n",
        "\n",
        "# Calcular la varianza de los estimadores\n",
        "fisher_info = sigma2_hat * XTX_1\n",
        "\n",
        "# Coeficiente estimado y su desviación estándar para female\n",
        "beta_female = beta_hat[-1]  # Último coeficiente (female)\n",
        "se_beta_female = np.sqrt(fisher_info[-1, -1])\n",
        "\n",
        "# Intervalo de confianza al 95%\n",
        "from scipy.stats import t\n",
        "\n",
        "alpha = 0.05\n",
        "t_critical = t.ppf(1 - alpha/2, df=X.shape[0] - X.shape[1])\n",
        "conf_interval = [beta_female - t_critical * se_beta_female, beta_female + t_critical * se_beta_female]\n",
        "\n",
        "print('Intervalo de confianza al 95% para el coeficiente de female:', conf_interval)"
      ],
      "metadata": {
        "id": "vBKSPCfrcnUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "v. Realizar una prueba de hipótesis para evaluar si la educación y el sexo tienen un efecto estadísticamente significativo sobre el salario."
      ],
      "metadata": {
        "id": "vsdACy2hbV2f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Coeficiente estimado y su desviación estándar para educ y female\n",
        "beta_educ = beta_hat[1]\n",
        "se_beta_educ = np.sqrt(fisher_info[1, 1])\n",
        "\n",
        "# Prueba t para educ\n",
        "t_stat_educ = beta_educ / se_beta_educ\n",
        "p_value_educ = 2 * (1 - t.cdf(np.abs(t_stat_educ), df=X.shape[0] - X.shape[1]))\n",
        "\n",
        "print('Estadístico t para educ:', t_stat_educ)\n",
        "print('p-valor para educ:', p_value_educ)\n",
        "\n",
        "# Prueba t para female\n",
        "t_stat_female = beta_female / se_beta_female\n",
        "p_value_female = 2 * (1 - t.cdf(np.abs(t_stat_female), df=X.shape[0] - X.shape[1]))\n",
        "\n",
        "print('Estadístico t para female:', t_stat_female)\n",
        "print('p-valor para female:', p_value_female)"
      ],
      "metadata": {
        "id": "YLtb1mD2bFzD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*BONUS: Estimacion mediante* `statsmodels`"
      ],
      "metadata": {
        "id": "uMIKTzJdfRLR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.formula.api as smf\n",
        "\n",
        "# Definir ecuación de regresión\n",
        "equation = 'lwage ~ educ + exper + expersq + female'\n",
        "\n",
        "# Ajustar el modelo por mínimos cuadrados (OLS)\n",
        "model = smf.ols(equation, data=df)\n",
        "\n",
        "# Estimar el modelo\n",
        "results = model.fit()\n",
        "\n",
        "# Imprimir resultados\n",
        "print(results.summary())"
      ],
      "metadata": {
        "id": "asdMpumGe6Lh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Práctica 3. Ejercicio 6\n",
        "\n",
        "Generar $n=100$ samples de $X_1 \\sim  \\mathcal{U}(0,1), Z\\sim \\mathcal{N}(0,0.01)$ y $\\varepsilon\\sim \\mathcal{N}(0,1)$. A partir de estas muestras generar $X_2= 0.5X_1+Z$ y de $Y=2+2X_1+0.3X_2 + \\varepsilon$\n",
        "\n",
        "a. Calcular la correlación entre las muestras de $X_1$ y $X_2$ y graficar su distribución conjunta.  \n",
        "b. Ajustar un modelo por mínimos cuadrados para predecir $Y$ usando como dato tanto $X_1$ como $X_2$. Describir los resultados obtenidos incluyendo los los coeficientes de regresión $\\hat\\beta_0, \\hat\\beta_1, \\hat\\beta_2$, y analizar la relación entre estos coeficientes y los verdaderos valores  $\\beta_0, \\beta_1, \\beta_2$  \n",
        "c. Ajustar modelos de regresión lineal por mínimos cuadrados para $Y$ y analizar resultados\n",
        "  - utilizando solamente datos de $X_1$ e $Y$\n",
        "  - utilizando solamente datos de $X_2$ e $Y$\n",
        "\n",
        "d. Graficar la distribución conjunta de $\\hat\\beta_1$ y $\\hat\\beta_2$"
      ],
      "metadata": {
        "id": "DdypLyZFgx7s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "# Número de muestras\n",
        "n = 100\n",
        "\n",
        "true_betas = [2,2,0.3]\n",
        "\n",
        "# Generar X1, Z y epsilon\n",
        "X1 = stats.uniform.rvs(0, 1, size=n)  # X1 ~ Uniform(0, 1)\n",
        "Z = stats.norm.rvs(0, 0.1, size=n)    # Z ~ Normal(0, 0.1)\n",
        "epsilon = stats.norm.rvs(0, 1, size=n) # epsilon ~ Normal(0, 1)\n",
        "\n",
        "# Generar X2\n",
        "X2 = 0.5 * X1 + Z\n",
        "\n",
        "# Armar matriz de diseño\n",
        "X = np.column_stack((np.ones(n),X1, X2))\n",
        "\n",
        "# Generary y\n",
        "y = X @ true_betas + epsilon"
      ],
      "metadata": {
        "id": "sRoFnwl_g0Vu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Calcular la correlación entre X1 y X2\n",
        "\n",
        "correlation_matrix = np.corrcoef(X1, X2)\n",
        "correlation_matrix[0,1]"
      ],
      "metadata": {
        "id": "M0PHtTEMjvqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ... y graficar su distribución conjunta\n",
        "\n",
        "fig, ax = plt.subplots(figsize = (12, 6))\n",
        "\n",
        "ax.scatter(X1, X2)\n",
        "ax.set_xlabel('X1')\n",
        "ax.set_ylabel('X2')\n",
        "ax.set_title('Distribución conjunta de X1 y X2')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "A-wfYaDVj4TJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ajustar un modelo por mínimos cuadrados para predecir $Y$ usando como dato tanto $X_1$ como $X_2$. Describir los resultados obtenidos incluyendo los los coeficientes de regresión $\\hat\\beta_0, \\hat\\beta_1, \\hat\\beta_2$, y analizar la relación entre estos coeficientes y los verdaderos valores  $\\beta_0,"
      ],
      "metadata": {
        "id": "3OdN16Ojkxku"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ajustar Y ~ X1 + X2 por MCO. Describir los resultados y comparar con los verdaderos valores de los parámetros"
      ],
      "metadata": {
        "id": "Vn_eFQxkkw8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "beta_hat = get_beta_hat(X, y)\n",
        "print('Estimadores:',beta_hat.round(3))\n",
        "print('Estimadores:',true_betas)"
      ],
      "metadata": {
        "id": "dx2YyoCuk6ha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# c. Estimar modelos utilizando...\n",
        "\n",
        "# ... solamente X1\n",
        "design_x1 = np.column_stack((np.ones(n),X1))\n",
        "beta_hat_x1 = get_beta_hat(design_x1, y)\n",
        "\n",
        "print('Estimación utilizando solamente X1:')\n",
        "print('Estimador:',beta_hat_x1[1].round(3))\n",
        "print('Parámetro:',true_betas[1])\n",
        "\n",
        "print('-'*30)\n",
        "\n",
        "# ... solamente X2\n",
        "print('Estimación utilizando solamente X2:')\n",
        "design_x2 = np.column_stack((np.ones(n),X2))\n",
        "beta_hat_x2 = get_beta_hat(design_x2, y)\n",
        "print('Estimador:',beta_hat_x2[1].round(3))\n",
        "print('Parámetro:',true_betas[2])"
      ],
      "metadata": {
        "id": "T8yqVzF5lBWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Graficar la distribución conjunta de beta_hat1 y beta_hat2\n",
        "\n",
        "# Para esto vamos a realizar un ejercicio de simulación\n",
        "\n",
        "\n",
        "# Número de repeticiones para la simulación\n",
        "num_simulations = 1000\n",
        "\n",
        "# Almacenar los coeficientes\n",
        "beta1_estimates = []\n",
        "beta2_estimates = []\n",
        "\n",
        "for _ in range(num_simulations):\n",
        "\n",
        "    # Generar error\n",
        "    epsilon = stats.norm.rvs(0, 1, size=n) # epsilon ~ Normal(0, 1)\n",
        "\n",
        "    # Generary y\n",
        "    y = X @ true_betas + epsilon\n",
        "\n",
        "    # Estimar por MCO\n",
        "    beta_hat = get_beta_hat(X, y)\n",
        "\n",
        "    # Almacenar coeficientes\n",
        "    beta1_estimates.append(beta_hat[1])\n",
        "    beta2_estimates.append(beta_hat[2])"
      ],
      "metadata": {
        "id": "EHups9JMnNVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Graficar la distribución conjunta\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.hexbin(beta1_estimates, beta2_estimates, gridsize=30, cmap='Blues')\n",
        "plt.colorbar(label='Frecuencia')\n",
        "plt.title('Distribución Conjunta de $\\hat{\\\\beta}_1$ y $\\hat{\\\\beta}_2$')\n",
        "plt.xlabel('$\\\\hat{\\\\beta}_1$')\n",
        "plt.ylabel('$\\\\hat{\\\\beta}_2$')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "0_AZxzfroHWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize = (8,6))\n",
        "\n",
        "ax.scatter(beta1_estimates, beta2_estimates, alpha=.3)\n",
        "\n",
        "plt.title('Distribución Conjunta de $\\hat{\\\\beta}_1$ y $\\hat{\\\\beta}_2$')\n",
        "ax.set_xlabel('$\\\\hat{\\\\beta}_1$')\n",
        "ax.set_ylabel('$\\\\hat{\\\\beta}_2$')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dRRCKl_ToVJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0Bw0ILYgo6jC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}